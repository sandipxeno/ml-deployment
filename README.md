# ml-deployment
We are collaboratively deploying an ML model using GitHub, Docker, CI/CD pipeline and GPU acceleration for scalable and automated inference.
